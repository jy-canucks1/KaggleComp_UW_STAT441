{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T18:05:09.052559Z",
     "start_time": "2024-03-27T18:05:06.992812Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # Import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from Dataset_OnlyOneHotEncodingApplied import *\n",
    "# # Set options\n",
    "# pd.options.display.max_rows = 999\n",
    "# pd.options.display.max_columns = 999\n",
    "\n",
    "# train_x_raw = pd.read_csv(\"../01-Data/X_train.csv\", low_memory = True, index_col=0)\n",
    "# train_y_raw = pd.read_csv(\"../01-Data/y_train.csv\", low_memory = True, index_col=0)\n",
    "# test_x_raw = pd.read_csv(\"../01-Data/X_test.csv\", low_memory=True, index_col=0)\n",
    "\n",
    "# df_train = pd.DataFrame(train_x_raw)\n",
    "# df_test = pd.DataFrame(test_x_raw)\n",
    "# df_y = pd.DataFrame(train_y_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92646daeb6719b84",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Simple Model Run\n",
    "##  xgBoost model set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5fbfcd048b55d241",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T18:05:10.537531Z",
     "start_time": "2024-03-27T18:05:09.758625Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "label_mapping = {-1: 0, 1: 1, 2: 2, 3: 3, 4: 4}\n",
    "df_y = df_y.replace(label_mapping)\n",
    "\n",
    "\n",
    "# dtrain = xgb.DMatrix(df_train, label=df_y, enable_categorical=True)\n",
    "# dtest = xgb.DMatrix(df_test, enable_categorical=True)\n",
    "\n",
    "\n",
    "import cupy as cp\n",
    "\n",
    "# Convert features and labels to Cupy arrays\n",
    "df_train_gpu = cp.asnumpy(df_train)\n",
    "df_y_gpu = cp.asnumpy(df_y)\n",
    "\n",
    "# Create DMatrix from Cupy arrays\n",
    "dtrain = xgb.DMatrix(df_train_gpu, label=df_y_gpu, enable_categorical=True)\n",
    "\n",
    "# Convert test data to Cupy arrays\n",
    "df_test_gpu = cp.asnumpy(df_test)\n",
    "\n",
    "# Create DMatrix for test data\n",
    "dtest = xgb.DMatrix(df_test_gpu, enable_categorical=True)\n",
    "\n",
    "\n",
    "params = {\n",
    "    'max_depth': 8,\n",
    "    'eta': 0.1,\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': 5,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'device' : 'cuda',\n",
    "    'predictor': 'gpu_predictor'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "num_boost_round = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781c354c",
   "metadata": {},
   "source": [
    "## Xgboost Model GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c2c65d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 48 candidates, totalling 144 fits\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=7; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=7; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=7; total time=   2.4s\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=7; total time=   2.5s\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=7; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=7; total time=   3.8s\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=7; total time=   2.9s\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=7; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=7; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:21:17] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=0; total time= 2.1min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:21:18] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:21:18] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=0; total time= 2.1min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=0; total time= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeonghan/.local/lib/python3.10/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:21:19] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=0; total time= 2.2min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:21:20] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:21:20] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=0; total time= 2.1min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=0; total time= 2.2min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=7; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=7; total time=   0.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:23:33] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:23:33] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:23:34] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=0; total time= 4.4min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=0; total time= 4.4min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=0; total time= 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:25:03] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=0.8; total time= 5.8min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:25:39] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=0.8; total time= 6.5min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:25:42] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:25:42] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=0.8; total time= 6.6min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=0.8; total time= 6.6min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=7; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=0; total time= 4.6min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=0; total time= 2.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:25:57] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=0; total time= 4.6min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=0; total time= 4.6min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=0.8; total time= 6.0min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=7; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=7; total time=   0.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:27:19] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=0.8; total time= 6.0min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:27:24] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=0; total time= 2.3min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=0; total time= 2.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:29:59] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=0.8; total time= 8.6min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=0; total time= 2.3min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=0; total time= 4.6min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=0; total time= 4.5min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=0; total time= 4.5min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=7; total time=   1.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:30:42] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=0.8; total time=11.6min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:30:45] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:30:49] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=0.8; total time=11.6min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=0.8; total time=11.7min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=0.8; total time= 8.5min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=0.8; total time= 8.5min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=0.8; total time= 6.3min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=0.8; total time= 6.3min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=7; total time=   1.6s\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=0.8; total time= 6.3min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:32:14] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=0; total time= 2.2min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=0; total time= 2.2min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=7; total time=   1.4s\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=7; total time=   1.1s\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=0; total time= 2.2min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=0; total time= 2.2min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=0; total time= 2.2min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=0; total time= 4.4min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=0.8; total time= 4.7min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=0.8; total time= 4.7min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=0.8; total time= 4.7min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=7; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=7; total time=   1.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:35:14] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=0; total time= 4.4min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [17:35:17] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=0; total time= 4.4min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=0.8; total time= 9.3min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=0.8; total time= 9.3min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=0.8; total time= 9.3min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=7; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=7; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=0; total time= 2.2min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=0; total time= 2.2min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=0; total time= 4.4min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=0; total time= 2.2min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=0.8; total time= 6.4min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=0.8; total time= 6.9min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=0.8; total time= 7.0min\n",
      "[CV] END colsample_bytree=0.7, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=0.8; total time= 7.0min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=7; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=7; total time=   2.0s\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=0; total time= 4.4min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=0; total time= 4.4min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=0.8; total time= 6.6min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=0.8; total time= 6.5min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=7; total time=   2.1s\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=7; total time=   1.9s\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=0; total time= 2.3min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=0; total time= 2.4min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=0.8; total time= 6.0min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=0; total time= 2.4min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=0; total time= 4.7min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=0.8; total time= 6.1min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=0; total time= 4.7min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=7; total time=   0.9s\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=0; total time= 4.7min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=7; total time=   1.7s\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=0.8; total time= 6.2min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=0.8; total time=11.8min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=0.8; total time=11.8min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=0.8; total time=11.8min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=7; total time=   1.8s\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=7; total time=   1.3s\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=7; total time=   0.8s\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=0; total time= 2.2min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=0; total time= 4.5min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=0.8; total time= 6.5min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=0.8; total time= 8.6min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=0.8; total time= 8.7min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.1, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=0.8; total time= 8.7min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=0; total time= 4.5min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=7; total time=   1.5s\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=7; total time=   1.2s\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=7; total time=   1.0s\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=0; total time= 4.5min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=0.8; total time= 6.5min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=500, subsample=0.8; total time= 6.5min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=0; total time= 2.1min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=0; total time= 2.1min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=0.8; total time= 3.9min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=0.8; total time= 3.9min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=0; total time= 3.6min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=500, subsample=0.8; total time= 3.8min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=0; total time= 3.5min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=0; total time= 3.5min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=0.8; total time= 7.9min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=0.8; total time= 7.9min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.05, max_depth=8, n_estimators=1000, subsample=0.8; total time= 7.9min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=0.8; total time= 4.0min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=0.8; total time= 3.9min\n",
      "[CV] END colsample_bytree=0.8, device=cuda, gamma=0.3, learning_rate=0.1, max_depth=8, n_estimators=1000, subsample=0.8; total time= 3.7min\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeonghan/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:547: FitFailedWarning: \n",
      "48 fits failed out of a total of 144.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "48 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/jeonghan/.local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 895, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/sklearn.py\", line 1519, in fit\n",
      "    self._Booster = train(\n",
      "  File \"/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py\", line 730, in inner_f\n",
      "    return func(**kwargs)\n",
      "  File \"/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/training.py\", line 181, in train\n",
      "    bst.update(dtrain, i, obj)\n",
      "  File \"/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py\", line 2050, in update\n",
      "    _check_call(\n",
      "  File \"/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py\", line 282, in _check_call\n",
      "    raise XGBoostError(py_str(_LIB.XGBGetLastError()))\n",
      "xgboost.core.XGBoostError: value 7 for Parameter subsample exceed bound [0,1]\n",
      "subsample: Row subsample ratio of training instance.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/jeonghan/.local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1051: UserWarning: One or more of the test scores are non-finite: [-1.6094379          nan -0.86018589 -1.6094379          nan -0.9083346\n",
      " -1.6094379          nan -0.92276188 -1.6094379          nan -0.93171122\n",
      " -1.6094379          nan -0.8559901  -1.6094379          nan -0.86739261\n",
      " -1.6094379          nan -0.87795306 -1.6094379          nan -0.88037917\n",
      " -1.6094379          nan -0.86156164 -1.6094379          nan -0.91002736\n",
      " -1.6094379          nan -0.92501228 -1.6094379          nan -0.93321605\n",
      " -1.6094379          nan -0.85757449 -1.6094379          nan -0.86889361\n",
      " -1.6094379          nan -0.87992828 -1.6094379          nan -0.88238861]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'colsample_bytree': 0.7, 'device': 'cuda', 'gamma': 0.3, 'learning_rate': 0.05, 'max_depth': 8, 'n_estimators': 500, 'subsample': 0.8}\n",
      "Best score (neg_log_loss):  -0.855990098390015\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import log_loss\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "# Assume df_train, df_test, and df_y are already defined and preprocessed\n",
    "# as per your setup\n",
    "\n",
    "# Define the parameter grid to search\n",
    "param_grid = {\n",
    "    'device' : ['cuda'],\n",
    "    'max_depth': [8],\n",
    "    'learning_rate': [0.05, 0.1],\n",
    "    'n_estimators': [500, 1000],\n",
    "    'subsample': [0,7, 0.8],\n",
    "    'gamma': [0.1, 0.3],\n",
    "    'colsample_bytree': [0.7, 0.8],\n",
    "}\n",
    "\n",
    "# Instantiate the XGBClassifier (note: use objective 'multi:softprob' for multi-class)\n",
    "xgb_model = XGBClassifier(objective='multi:softprob', num_class=5, eval_metric='mlogloss', use_label_encoder=False,device='cuda')\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, scoring='neg_log_loss', n_jobs=-1, cv=3, verbose=2)\n",
    "\n",
    "# Fit the GridSearchCV object to find the best parameters\n",
    "grid_search.fit(df_train_gpu, df_y_gpu)\n",
    "\n",
    "# Best parameter set found\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "\n",
    "# Best score\n",
    "print(\"Best score (neg_log_loss): \", grid_search.best_score_)\n",
    "\n",
    "# You can also use the best estimator directly to make predictions\n",
    "# best_estimator = grid_search.best_estimator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73377ae83e283639",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6d6fdecf41fb2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T18:06:42.022458Z",
     "start_time": "2024-03-27T18:05:10.540713Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [14:06:54] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/jeonghan/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [14:06:55] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "ename": "XGBoostError",
     "evalue": "[14:06:55] /workspace/src/metric/multiclass_metric.cu:35: Check failed: label_error >= 0 && label_error < static_cast<int32_t>(n_class): MultiClassEvaluation: label must be in [0, num_class), num_class=1 but found 3 in label\nStack trace:\n  [bt] (0) /home/jeonghan/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x1ba24e) [0x7fcef228224e]\n  [bt] (1) /home/jeonghan/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x9a5666) [0x7fcef2a6d666]\n  [bt] (2) /home/jeonghan/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x4efea5) [0x7fcef25b7ea5]\n  [bt] (3) /home/jeonghan/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x4f0168) [0x7fcef25b8168]\n  [bt] (4) /home/jeonghan/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x4c8ab0) [0x7fcef2590ab0]\n  [bt] (5) /home/jeonghan/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(XGBoosterEvalOneIter+0x2f6) [0x7fcef2232bb6]\n  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7fcf88c40e2e]\n  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7fcf88c3d493]\n  [bt] (8) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa3e9) [0x7fcf88eaa3e9]\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cv\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# params and num_boost_round provided above\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m xgb_cv \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnfold\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmlogloss\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_pandas\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m123\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m xgb_cv\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/training.py:572\u001b[0m, in \u001b[0;36mcv\u001b[0;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle, custom_metric)\u001b[0m\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    570\u001b[0m booster\u001b[38;5;241m.\u001b[39mupdate(i, obj)\n\u001b[0;32m--> 572\u001b[0m should_break \u001b[38;5;241m=\u001b[39m \u001b[43mcallbacks_container\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbooster\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    573\u001b[0m res \u001b[38;5;241m=\u001b[39m callbacks_container\u001b[38;5;241m.\u001b[39maggregated_cv\n\u001b[1;32m    574\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, mean, std \u001b[38;5;129;01min\u001b[39;00m cast(List[Tuple[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]], res):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/callback.py:230\u001b[0m, in \u001b[0;36mCallbackContainer.after_iteration\u001b[0;34m(self, model, epoch, dtrain, evals)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Function called after training iteration.\"\"\"\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_cv:\n\u001b[0;32m--> 230\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_output_margin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m     scores \u001b[38;5;241m=\u001b[39m _aggcv(scores)\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregated_cv \u001b[38;5;241m=\u001b[39m scores\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/training.py:235\u001b[0m, in \u001b[0;36m_PackedBooster.eval\u001b[0;34m(self, iteration, feval, output_margin)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval\u001b[39m(\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m, iteration: \u001b[38;5;28mint\u001b[39m, feval: Optional[Metric], output_margin: \u001b[38;5;28mbool\u001b[39m\n\u001b[1;32m    233\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    234\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Iterate through folds for eval\"\"\"\u001b[39;00m\n\u001b[0;32m--> 235\u001b[0m     result \u001b[38;5;241m=\u001b[39m [f\u001b[38;5;241m.\u001b[39meval(iteration, feval, output_margin) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcvfolds]\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/training.py:235\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval\u001b[39m(\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m, iteration: \u001b[38;5;28mint\u001b[39m, feval: Optional[Metric], output_margin: \u001b[38;5;28mbool\u001b[39m\n\u001b[1;32m    233\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    234\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Iterate through folds for eval\"\"\"\u001b[39;00m\n\u001b[0;32m--> 235\u001b[0m     result \u001b[38;5;241m=\u001b[39m [\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcvfolds]\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/training.py:219\u001b[0m, in \u001b[0;36mCVPack.eval\u001b[0;34m(self, iteration, feval, output_margin)\u001b[0m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21meval\u001b[39m(\u001b[38;5;28mself\u001b[39m, iteration: \u001b[38;5;28mint\u001b[39m, feval: Optional[Metric], output_margin: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    218\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\" \"Evaluate the CVPack for one iteration.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 219\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_set\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwatchlist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:2125\u001b[0m, in \u001b[0;36mBooster.eval_set\u001b[0;34m(self, evals, iteration, feval, output_margin)\u001b[0m\n\u001b[1;32m   2123\u001b[0m evnames \u001b[38;5;241m=\u001b[39m c_array(ctypes\u001b[38;5;241m.\u001b[39mc_char_p, [c_str(d[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m evals])\n\u001b[1;32m   2124\u001b[0m msg \u001b[38;5;241m=\u001b[39m ctypes\u001b[38;5;241m.\u001b[39mc_char_p()\n\u001b[0;32m-> 2125\u001b[0m \u001b[43m_check_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2126\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterEvalOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2128\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2129\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdmats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2130\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2131\u001b[0m \u001b[43m        \u001b[49m\u001b[43mc_bst_ulong\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2132\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2133\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2135\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m msg\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   2136\u001b[0m res \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;241m.\u001b[39mdecode()  \u001b[38;5;66;03m# pylint: disable=no-member\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:282\u001b[0m, in \u001b[0;36m_check_call\u001b[0;34m(ret)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Check the return value of C API call\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \n\u001b[1;32m    273\u001b[0m \u001b[38;5;124;03mThis function will raise exception when error occurs.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;124;03m    return value from API calls\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 282\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m XGBoostError(py_str(_LIB\u001b[38;5;241m.\u001b[39mXGBGetLastError()))\n",
      "\u001b[0;31mXGBoostError\u001b[0m: [14:06:55] /workspace/src/metric/multiclass_metric.cu:35: Check failed: label_error >= 0 && label_error < static_cast<int32_t>(n_class): MultiClassEvaluation: label must be in [0, num_class), num_class=1 but found 3 in label\nStack trace:\n  [bt] (0) /home/jeonghan/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x1ba24e) [0x7fcef228224e]\n  [bt] (1) /home/jeonghan/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x9a5666) [0x7fcef2a6d666]\n  [bt] (2) /home/jeonghan/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x4efea5) [0x7fcef25b7ea5]\n  [bt] (3) /home/jeonghan/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x4f0168) [0x7fcef25b8168]\n  [bt] (4) /home/jeonghan/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(+0x4c8ab0) [0x7fcef2590ab0]\n  [bt] (5) /home/jeonghan/.local/lib/python3.10/site-packages/xgboost/lib/libxgboost.so(XGBoosterEvalOneIter+0x2f6) [0x7fcef2232bb6]\n  [bt] (6) /lib/x86_64-linux-gnu/libffi.so.8(+0x7e2e) [0x7fcf88c40e2e]\n  [bt] (7) /lib/x86_64-linux-gnu/libffi.so.8(+0x4493) [0x7fcf88c3d493]\n  [bt] (8) /usr/lib/python3.10/lib-dynload/_ctypes.cpython-310-x86_64-linux-gnu.so(+0xa3e9) [0x7fcf88eaa3e9]\n\n"
     ]
    }
   ],
   "source": [
    "from xgboost import cv\n",
    "\n",
    "# params and num_boost_round provided above\n",
    "xgb_cv = cv(dtrain=dtrain, params=params, nfold=10,\n",
    "            num_boost_round=num_boost_round, early_stopping_rounds=5,\n",
    "            metrics=\"mlogloss\", as_pandas=True, seed=123)\n",
    "\n",
    "xgb_cv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf3eff0c1cff4b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Xgboost Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e33513991df267c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T18:07:06.878598Z",
     "start_time": "2024-03-27T18:06:42.025685Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Multiclass Logarithmic Loss: 0.7841006598490445\n",
      "Validation Multiclass Logarithmic Loss: 0.7841006488289419\n"
     ]
    }
   ],
   "source": [
    "evals_result = {}\n",
    "bst = xgb.train(params, dtrain, num_boost_round, \n",
    "                evals=[(dtrain, 'train')], evals_result=evals_result, \n",
    "                verbose_eval=False)\n",
    "print(f\"Training Multiclass Logarithmic Loss: {evals_result['train']['mlogloss'][-1]}\")\n",
    "\n",
    "y_test_probs = bst.predict(dtest)\n",
    "\n",
    "class_order = [0, 1, 2, 3, 4]\n",
    "class_mapping = {class_label: f\"Class_{class_label}\" for class_label in class_order}\n",
    "\n",
    "y_train_probs = bst.predict(dtrain)\n",
    "val_log_loss = log_loss(df_y, y_train_probs, labels=class_order)\n",
    "print(f\"Validation Multiclass Logarithmic Loss: {val_log_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1527521c5801211",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generate Submission csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae6668498e2687f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-27T18:07:06.910218Z",
     "start_time": "2024-03-27T18:07:06.882783Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(y_test_probs, columns=class_mapping.values())\n",
    "submission_df.columns = ['no answer', 'very important', 'quite important', 'not important', 'not at all important']\n",
    "submission_df.insert(0, 'id', df_test.index)\n",
    "\n",
    "# Save the submission file\n",
    "# submission_file = ('submission.csv')\n",
    "# submission_df.to_csv(submission_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
