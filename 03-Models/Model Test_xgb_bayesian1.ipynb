{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-30T04:46:16.168167Z",
     "start_time": "2024-03-30T04:45:57.112877Z"
    }
   },
   "outputs": [],
   "source": [
    "from Dataset_HCR_ICIR_OHE_applied import *\n",
    "# train_x_raw = pd.read_csv(\"../01-Data/X_train.csv\", low_memory = True, index_col=0)\n",
    "# train_y_raw = pd.read_csv(\"../01-Data/y_train.csv\", low_memory = True, index_col=0)\n",
    "# test_x_raw = pd.read_csv(\"../01-Data/X_test.csv\", low_memory=True, index_col=0)\n",
    "\n",
    "# df_train = pd.DataFrame(train_x_raw)\n",
    "# df_test = pd.DataFrame(test_x_raw)\n",
    "# df_y = pd.DataFrame(train_y_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92646daeb6719b84",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Simple Model Run\n",
    "##  xgBoost model set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b65d6aaf6aa41b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-30T04:46:48.062512Z",
     "start_time": "2024-03-30T04:46:48.052587Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Remap labels\n",
    "label_mapping = {-1: 0, 1: 1, 2: 2, 3: 3, 4: 4}\n",
    "df_y = df_y.replace(label_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1d5d02b4bf4f48",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f51e53c89851a293",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-30T04:16:50.833036Z",
     "start_time": "2024-03-30T02:31:15.635562Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... |    eta    |   gamma   | max_depth | min_ch... | reg_alpha | reg_la... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m1        \u001b[0m | \u001b[0m-0.8494  \u001b[0m | \u001b[0m0.6124   \u001b[0m | \u001b[0m0.1906   \u001b[0m | \u001b[0m2.955    \u001b[0m | \u001b[0m5.395    \u001b[0m | \u001b[0m1.624    \u001b[0m | \u001b[0m0.078    \u001b[0m | \u001b[0m0.7033   \u001b[0m | \u001b[0m0.7599   \u001b[0m |\n",
      "| \u001b[0m2        \u001b[0m | \u001b[0m-0.8496  \u001b[0m | \u001b[0m0.6803   \u001b[0m | \u001b[0m0.1445   \u001b[0m | \u001b[0m0.1803   \u001b[0m | \u001b[0m6.88     \u001b[0m | \u001b[0m4.33     \u001b[0m | \u001b[0m0.1062   \u001b[0m | \u001b[0m1.136    \u001b[0m | \u001b[0m0.555    \u001b[0m |\n",
      "| \u001b[95m3        \u001b[0m | \u001b[95m-0.8468  \u001b[0m | \u001b[95m0.5913   \u001b[0m | \u001b[95m0.1097   \u001b[0m | \u001b[95m1.785    \u001b[0m | \u001b[95m4.165    \u001b[0m | \u001b[95m3.447    \u001b[0m | \u001b[95m0.06975  \u001b[0m | \u001b[95m1.523    \u001b[0m | \u001b[95m0.6099   \u001b[0m |\n",
      "| \u001b[0m4        \u001b[0m | \u001b[0m-0.8501  \u001b[0m | \u001b[0m0.6368   \u001b[0m | \u001b[0m0.1592   \u001b[0m | \u001b[0m0.8787   \u001b[0m | \u001b[0m5.057    \u001b[0m | \u001b[0m3.37     \u001b[0m | \u001b[0m0.02323  \u001b[0m | \u001b[0m2.626    \u001b[0m | \u001b[0m0.5512   \u001b[0m |\n",
      "| \u001b[0m5        \u001b[0m | \u001b[0m-0.8494  \u001b[0m | \u001b[0m0.5195   \u001b[0m | \u001b[0m0.1903   \u001b[0m | \u001b[0m3.866    \u001b[0m | \u001b[0m6.234    \u001b[0m | \u001b[0m2.218    \u001b[0m | \u001b[0m0.04884  \u001b[0m | \u001b[0m2.895    \u001b[0m | \u001b[0m0.632    \u001b[0m |\n",
      "| \u001b[95m6        \u001b[0m | \u001b[95m-0.842   \u001b[0m | \u001b[95m0.5366   \u001b[0m | \u001b[95m0.1041   \u001b[0m | \u001b[95m0.2341   \u001b[0m | \u001b[95m6.637    \u001b[0m | \u001b[95m2.035    \u001b[0m | \u001b[95m0.3313   \u001b[0m | \u001b[95m1.591    \u001b[0m | \u001b[95m0.656    \u001b[0m |\n",
      "| \u001b[0m7        \u001b[0m | \u001b[0m-0.8439  \u001b[0m | \u001b[0m0.664    \u001b[0m | \u001b[0m0.04512  \u001b[0m | \u001b[0m3.881    \u001b[0m | \u001b[0m6.101    \u001b[0m | \u001b[0m4.758    \u001b[0m | \u001b[0m0.4474   \u001b[0m | \u001b[0m2.593    \u001b[0m | \u001b[0m0.7766   \u001b[0m |\n",
      "| \u001b[0m8        \u001b[0m | \u001b[0m-0.8441  \u001b[0m | \u001b[0m0.5265   \u001b[0m | \u001b[0m0.04724  \u001b[0m | \u001b[0m0.2764   \u001b[0m | \u001b[0m4.301    \u001b[0m | \u001b[0m2.555    \u001b[0m | \u001b[0m0.1357   \u001b[0m | \u001b[0m3.401    \u001b[0m | \u001b[0m0.607    \u001b[0m |\n",
      "| \u001b[0m9        \u001b[0m | \u001b[0m-0.8448  \u001b[0m | \u001b[0m0.5843   \u001b[0m | \u001b[0m0.1131   \u001b[0m | \u001b[0m0.6496   \u001b[0m | \u001b[0m6.209    \u001b[0m | \u001b[0m1.298    \u001b[0m | \u001b[0m0.4934   \u001b[0m | \u001b[0m3.203    \u001b[0m | \u001b[0m0.5596   \u001b[0m |\n",
      "| \u001b[0m10       \u001b[0m | \u001b[0m-0.8501  \u001b[0m | \u001b[0m0.5017   \u001b[0m | \u001b[0m0.1649   \u001b[0m | \u001b[0m2.857    \u001b[0m | \u001b[0m5.916    \u001b[0m | \u001b[0m4.085    \u001b[0m | \u001b[0m0.03702  \u001b[0m | \u001b[0m1.755    \u001b[0m | \u001b[0m0.5348   \u001b[0m |\n",
      "| \u001b[0m11       \u001b[0m | \u001b[0m-0.8487  \u001b[0m | \u001b[0m0.5937   \u001b[0m | \u001b[0m0.1731   \u001b[0m | \u001b[0m0.2855   \u001b[0m | \u001b[0m4.392    \u001b[0m | \u001b[0m2.579    \u001b[0m | \u001b[0m0.3094   \u001b[0m | \u001b[0m3.261    \u001b[0m | \u001b[0m0.7183   \u001b[0m |\n",
      "| \u001b[0m12       \u001b[0m | \u001b[0m-0.8534  \u001b[0m | \u001b[0m0.6503   \u001b[0m | \u001b[0m0.1759   \u001b[0m | \u001b[0m3.606    \u001b[0m | \u001b[0m3.318    \u001b[0m | \u001b[0m4.331    \u001b[0m | \u001b[0m0.2663   \u001b[0m | \u001b[0m2.751    \u001b[0m | \u001b[0m0.5346   \u001b[0m |\n",
      "| \u001b[0m13       \u001b[0m | \u001b[0m-0.8491  \u001b[0m | \u001b[0m0.5409   \u001b[0m | \u001b[0m0.138    \u001b[0m | \u001b[0m2.094    \u001b[0m | \u001b[0m3.105    \u001b[0m | \u001b[0m1.222    \u001b[0m | \u001b[0m0.124    \u001b[0m | \u001b[0m3.899    \u001b[0m | \u001b[0m0.7369   \u001b[0m |\n",
      "| \u001b[0m14       \u001b[0m | \u001b[0m-0.848   \u001b[0m | \u001b[0m0.6644   \u001b[0m | \u001b[0m0.1833   \u001b[0m | \u001b[0m0.4297   \u001b[0m | \u001b[0m4.797    \u001b[0m | \u001b[0m1.795    \u001b[0m | \u001b[0m0.2953   \u001b[0m | \u001b[0m1.86     \u001b[0m | \u001b[0m0.6869   \u001b[0m |\n",
      "| \u001b[0m15       \u001b[0m | \u001b[0m-0.8531  \u001b[0m | \u001b[0m0.5785   \u001b[0m | \u001b[0m0.1658   \u001b[0m | \u001b[0m3.92     \u001b[0m | \u001b[0m3.605    \u001b[0m | \u001b[0m4.373    \u001b[0m | \u001b[0m0.3738   \u001b[0m | \u001b[0m2.781    \u001b[0m | \u001b[0m0.772    \u001b[0m |\n",
      "| \u001b[0m16       \u001b[0m | \u001b[0m-0.8434  \u001b[0m | \u001b[0m0.6911   \u001b[0m | \u001b[0m0.09491  \u001b[0m | \u001b[0m2.703    \u001b[0m | \u001b[0m5.814    \u001b[0m | \u001b[0m4.418    \u001b[0m | \u001b[0m0.3203   \u001b[0m | \u001b[0m3.088    \u001b[0m | \u001b[0m0.6431   \u001b[0m |\n",
      "| \u001b[0m17       \u001b[0m | \u001b[0m-0.8506  \u001b[0m | \u001b[0m0.7017   \u001b[0m | \u001b[0m0.1574   \u001b[0m | \u001b[0m0.7338   \u001b[0m | \u001b[0m3.516    \u001b[0m | \u001b[0m2.38     \u001b[0m | \u001b[0m0.01424  \u001b[0m | \u001b[0m0.9169   \u001b[0m | \u001b[0m0.7851   \u001b[0m |\n",
      "| \u001b[95m18       \u001b[0m | \u001b[95m-0.8413  \u001b[0m | \u001b[95m0.5349   \u001b[0m | \u001b[95m0.02248  \u001b[0m | \u001b[95m0.2386   \u001b[0m | \u001b[95m6.666    \u001b[0m | \u001b[95m1.87     \u001b[0m | \u001b[95m0.2135   \u001b[0m | \u001b[95m1.81     \u001b[0m | \u001b[95m0.6956   \u001b[0m |\n",
      "| \u001b[0m19       \u001b[0m | \u001b[0m-0.8469  \u001b[0m | \u001b[0m0.7585   \u001b[0m | \u001b[0m0.1381   \u001b[0m | \u001b[0m0.3944   \u001b[0m | \u001b[0m5.073    \u001b[0m | \u001b[0m2.081    \u001b[0m | \u001b[0m0.3379   \u001b[0m | \u001b[0m2.196    \u001b[0m | \u001b[0m0.6861   \u001b[0m |\n",
      "| \u001b[0m20       \u001b[0m | \u001b[0m-0.8624  \u001b[0m | \u001b[0m0.5405   \u001b[0m | \u001b[0m0.01534  \u001b[0m | \u001b[0m1.977    \u001b[0m | \u001b[0m5.898    \u001b[0m | \u001b[0m4.612    \u001b[0m | \u001b[0m0.07505  \u001b[0m | \u001b[0m3.396    \u001b[0m | \u001b[0m0.6981   \u001b[0m |\n",
      "| \u001b[0m21       \u001b[0m | \u001b[0m-0.8438  \u001b[0m | \u001b[0m0.5842   \u001b[0m | \u001b[0m0.1149   \u001b[0m | \u001b[0m0.3154   \u001b[0m | \u001b[0m6.334    \u001b[0m | \u001b[0m1.959    \u001b[0m | \u001b[0m0.3667   \u001b[0m | \u001b[0m1.887    \u001b[0m | \u001b[0m0.6492   \u001b[0m |\n",
      "| \u001b[95m22       \u001b[0m | \u001b[95m-0.8371  \u001b[0m | \u001b[95m0.5845   \u001b[0m | \u001b[95m0.03626  \u001b[0m | \u001b[95m0.4015   \u001b[0m | \u001b[95m6.755    \u001b[0m | \u001b[95m2.232    \u001b[0m | \u001b[95m0.03545  \u001b[0m | \u001b[95m1.848    \u001b[0m | \u001b[95m0.6261   \u001b[0m |\n",
      "| \u001b[0m23       \u001b[0m | \u001b[0m-0.8457  \u001b[0m | \u001b[0m0.7877   \u001b[0m | \u001b[0m0.01973  \u001b[0m | \u001b[0m2.551    \u001b[0m | \u001b[0m6.398    \u001b[0m | \u001b[0m1.254    \u001b[0m | \u001b[0m0.2166   \u001b[0m | \u001b[0m0.5041   \u001b[0m | \u001b[0m0.5156   \u001b[0m |\n",
      "| \u001b[0m24       \u001b[0m | \u001b[0m-0.846   \u001b[0m | \u001b[0m0.5867   \u001b[0m | \u001b[0m0.1035   \u001b[0m | \u001b[0m0.654    \u001b[0m | \u001b[0m7.0      \u001b[0m | \u001b[0m2.126    \u001b[0m | \u001b[0m0.1502   \u001b[0m | \u001b[0m1.88     \u001b[0m | \u001b[0m0.5569   \u001b[0m |\n",
      "| \u001b[0m25       \u001b[0m | \u001b[0m-0.8395  \u001b[0m | \u001b[0m0.7076   \u001b[0m | \u001b[0m0.04893  \u001b[0m | \u001b[0m2.936    \u001b[0m | \u001b[0m6.46     \u001b[0m | \u001b[0m1.281    \u001b[0m | \u001b[0m0.04809  \u001b[0m | \u001b[0m1.158    \u001b[0m | \u001b[0m0.68     \u001b[0m |\n",
      "| \u001b[0m26       \u001b[0m | \u001b[0m-0.8792  \u001b[0m | \u001b[0m0.5714   \u001b[0m | \u001b[0m0.01     \u001b[0m | \u001b[0m0.1164   \u001b[0m | \u001b[0m6.648    \u001b[0m | \u001b[0m2.334    \u001b[0m | \u001b[0m0.0      \u001b[0m | \u001b[0m1.868    \u001b[0m | \u001b[0m0.7244   \u001b[0m |\n",
      "| \u001b[0m27       \u001b[0m | \u001b[0m-0.8514  \u001b[0m | \u001b[0m0.7172   \u001b[0m | \u001b[0m0.05425  \u001b[0m | \u001b[0m0.6357   \u001b[0m | \u001b[0m3.547    \u001b[0m | \u001b[0m4.11     \u001b[0m | \u001b[0m0.3227   \u001b[0m | \u001b[0m1.349    \u001b[0m | \u001b[0m0.6516   \u001b[0m |\n",
      "| \u001b[0m28       \u001b[0m | \u001b[0m-0.8377  \u001b[0m | \u001b[0m0.7235   \u001b[0m | \u001b[0m0.05904  \u001b[0m | \u001b[0m1.008    \u001b[0m | \u001b[0m6.78     \u001b[0m | \u001b[0m1.092    \u001b[0m | \u001b[0m0.2914   \u001b[0m | \u001b[0m2.767    \u001b[0m | \u001b[0m0.766    \u001b[0m |\n",
      "| \u001b[0m29       \u001b[0m | \u001b[0m-0.8421  \u001b[0m | \u001b[0m0.6255   \u001b[0m | \u001b[0m0.0766   \u001b[0m | \u001b[0m2.257    \u001b[0m | \u001b[0m4.776    \u001b[0m | \u001b[0m3.457    \u001b[0m | \u001b[0m0.0591   \u001b[0m | \u001b[0m1.622    \u001b[0m | \u001b[0m0.7505   \u001b[0m |\n",
      "| \u001b[0m30       \u001b[0m | \u001b[0m-0.8403  \u001b[0m | \u001b[0m0.6973   \u001b[0m | \u001b[0m0.08139  \u001b[0m | \u001b[0m1.022    \u001b[0m | \u001b[0m6.665    \u001b[0m | \u001b[0m1.112    \u001b[0m | \u001b[0m0.289    \u001b[0m | \u001b[0m2.725    \u001b[0m | \u001b[0m0.741    \u001b[0m |\n",
      "| \u001b[0m31       \u001b[0m | \u001b[0m-0.8396  \u001b[0m | \u001b[0m0.5469   \u001b[0m | \u001b[0m0.06424  \u001b[0m | \u001b[0m0.2761   \u001b[0m | \u001b[0m6.569    \u001b[0m | \u001b[0m1.79     \u001b[0m | \u001b[0m0.2121   \u001b[0m | \u001b[0m1.791    \u001b[0m | \u001b[0m0.5547   \u001b[0m |\n",
      "| \u001b[0m32       \u001b[0m | \u001b[0m-0.846   \u001b[0m | \u001b[0m0.7304   \u001b[0m | \u001b[0m0.1188   \u001b[0m | \u001b[0m3.045    \u001b[0m | \u001b[0m6.395    \u001b[0m | \u001b[0m1.253    \u001b[0m | \u001b[0m0.003166 \u001b[0m | \u001b[0m0.8654   \u001b[0m | \u001b[0m0.6526   \u001b[0m |\n",
      "| \u001b[0m33       \u001b[0m | \u001b[0m-0.8453  \u001b[0m | \u001b[0m0.5737   \u001b[0m | \u001b[0m0.01966  \u001b[0m | \u001b[0m0.3592   \u001b[0m | \u001b[0m6.591    \u001b[0m | \u001b[0m1.816    \u001b[0m | \u001b[0m0.1831   \u001b[0m | \u001b[0m1.603    \u001b[0m | \u001b[0m0.5665   \u001b[0m |\n",
      "| \u001b[0m34       \u001b[0m | \u001b[0m-0.8373  \u001b[0m | \u001b[0m0.6179   \u001b[0m | \u001b[0m0.05432  \u001b[0m | \u001b[0m0.8985   \u001b[0m | \u001b[0m6.889    \u001b[0m | \u001b[0m1.091    \u001b[0m | \u001b[0m0.3814   \u001b[0m | \u001b[0m2.768    \u001b[0m | \u001b[0m0.6197   \u001b[0m |\n",
      "| \u001b[0m35       \u001b[0m | \u001b[0m-0.8453  \u001b[0m | \u001b[0m0.6592   \u001b[0m | \u001b[0m0.1388   \u001b[0m | \u001b[0m0.5809   \u001b[0m | \u001b[0m6.638    \u001b[0m | \u001b[0m2.012    \u001b[0m | \u001b[0m0.3323   \u001b[0m | \u001b[0m1.809    \u001b[0m | \u001b[0m0.725    \u001b[0m |\n",
      "| \u001b[0m36       \u001b[0m | \u001b[0m-0.8442  \u001b[0m | \u001b[0m0.6589   \u001b[0m | \u001b[0m0.09367  \u001b[0m | \u001b[0m3.059    \u001b[0m | \u001b[0m6.51     \u001b[0m | \u001b[0m1.134    \u001b[0m | \u001b[0m0.009218 \u001b[0m | \u001b[0m1.2      \u001b[0m | \u001b[0m0.5675   \u001b[0m |\n",
      "| \u001b[0m37       \u001b[0m | \u001b[0m-0.8375  \u001b[0m | \u001b[0m0.664    \u001b[0m | \u001b[0m0.0315   \u001b[0m | \u001b[0m0.4132   \u001b[0m | \u001b[0m6.808    \u001b[0m | \u001b[0m2.121    \u001b[0m | \u001b[0m0.2202   \u001b[0m | \u001b[0m1.933    \u001b[0m | \u001b[0m0.6285   \u001b[0m |\n",
      "| \u001b[95m38       \u001b[0m | \u001b[95m-0.8354  \u001b[0m | \u001b[95m0.521    \u001b[0m | \u001b[95m0.03901  \u001b[0m | \u001b[95m0.4571   \u001b[0m | \u001b[95m6.976    \u001b[0m | \u001b[95m2.235    \u001b[0m | \u001b[95m0.00224  \u001b[0m | \u001b[95m1.898    \u001b[0m | \u001b[95m0.7271   \u001b[0m |\n",
      "| \u001b[0m39       \u001b[0m | \u001b[0m-0.8637  \u001b[0m | \u001b[0m0.7575   \u001b[0m | \u001b[0m0.0148   \u001b[0m | \u001b[0m1.282    \u001b[0m | \u001b[0m5.214    \u001b[0m | \u001b[0m2.81     \u001b[0m | \u001b[0m0.4484   \u001b[0m | \u001b[0m2.52     \u001b[0m | \u001b[0m0.6293   \u001b[0m |\n",
      "| \u001b[0m40       \u001b[0m | \u001b[0m-0.8465  \u001b[0m | \u001b[0m0.7537   \u001b[0m | \u001b[0m0.1576   \u001b[0m | \u001b[0m0.6574   \u001b[0m | \u001b[0m6.919    \u001b[0m | \u001b[0m1.065    \u001b[0m | \u001b[0m0.4273   \u001b[0m | \u001b[0m2.733    \u001b[0m | \u001b[0m0.7858   \u001b[0m |\n",
      "=========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "def xgb_cv_score(max_depth, gamma, colsample_bytree, subsample, eta, reg_lambda, reg_alpha, min_child_weight):\n",
    "    \"\"\"\n",
    "    Computes the cross-validated log loss for given hyperparameter settings using Stratified K-Fold.\n",
    "    \"\"\"\n",
    "    params = {\n",
    "       # 'device': 'cuda',\n",
    "        'max_depth': int(max_depth),\n",
    "        'gamma': gamma,\n",
    "        'colsample_bytree': colsample_bytree,\n",
    "        'subsample': subsample,\n",
    "        'eta': eta,\n",
    "        'objective': 'multi:softprob',\n",
    "        'num_class': 5,\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'lambda': reg_lambda,\n",
    "        'alpha': reg_alpha,\n",
    "        'min_child_weight': min_child_weight,\n",
    "        'verbosity': 0,\n",
    "        'seed': 42\n",
    "    }\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    log_loss_scores = []\n",
    "\n",
    "    for train_index, test_index in skf.split(df_train, df_y):\n",
    "        xgb_train = xgb.DMatrix(df_train.iloc[train_index], label=df_y.iloc[train_index])\n",
    "        xgb_valid = xgb.DMatrix(df_train.iloc[test_index], label=df_y.iloc[test_index])\n",
    "        \n",
    "        watchlist = [(xgb_train, 'train'), (xgb_valid, 'eval')]\n",
    "\n",
    "        # Add early_stopping_rounds\n",
    "        model = xgb.train(params, xgb_train, num_boost_round=500, evals=watchlist, early_stopping_rounds=10, verbose_eval=False)\n",
    "\n",
    "        # Predict using the best iteration\n",
    "        preds = model.predict(xgb_valid)\n",
    "        #preds = model.predict(xgb_valid, ntree_limit=(model.best_iteration + 1) * params['num_class']\n",
    "\n",
    "        log_loss_score = log_loss(df_y.iloc[test_index], preds, labels=list(range(5)))\n",
    "        log_loss_scores.append(log_loss_score)\n",
    "\n",
    "    return -np.mean(log_loss_scores)\n",
    "\n",
    "# Define the hyperparameter bounds\n",
    "pbounds = {\n",
    "    'max_depth': (3, 7),  # Reduced upper limit to prevent overfitting and reduce complexity.\n",
    "    'gamma': (0.1, 4),  # Expanded to include lower values, allowing for less aggressive regularization at the low end.\n",
    "    'colsample_bytree': (0.5, 0.8),  # Narrowed to focus on moderately high feature sampling for balance between performance and overfitting.\n",
    "    'subsample': (0.5, 0.8),  # Similar to colsample_bytree, aiming for a balance in sampling.\n",
    "    'eta': (0.01, 0.2),  # Narrowed upper limit to focus on more stable, albeit potentially slower, learning rates.\n",
    "    'reg_lambda': (0.5, 4),  # Expanded lower bound to allow for less regularization, adjusted upper limit to prevent overly strong L2 regularization.\n",
    "    'reg_alpha': (0, 0.5),  # Reduced upper limit to focus on lower levels of L1 regularization, preventing sparsity from being too aggressive.\n",
    "    'min_child_weight': (1, 5),  # Narrowed to prevent overly conservative model by avoiding too large values.\n",
    "}\n",
    "\n",
    "# Perform Bayesian Optimization\n",
    "optimizer = BayesianOptimization(f=xgb_cv_score, pbounds=pbounds, random_state=42, verbose=2)\n",
    "optimizer.maximize(init_points=10, n_iter=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d51ffd766a3e1d0a",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## CV xgboost train with best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8b6e0279574ad22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-30T04:49:31.736220Z",
     "start_time": "2024-03-30T04:49:11.645700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(df_train, df_y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Best parameters from optimization\n",
    "best_params = {\n",
    "    'max_depth': int(optimizer.max['params']['max_depth']),\n",
    "    'gamma': 3,\n",
    "    'colsample_bytree': optimizer.max['params']['colsample_bytree'],\n",
    "    'subsample': optimizer.max['params']['subsample'],\n",
    "    'eta': optimizer.max['params']['eta'],\n",
    "    'lambda': optimizer.max['params']['reg_lambda'],\n",
    "    'alpha': optimizer.max['params']['reg_alpha'],\n",
    "    'min_child_weight': optimizer.max['params']['min_child_weight'],\n",
    "    'objective': 'multi:softprob',\n",
    "    'num_class': 5,\n",
    "    'eval_metric': 'mlogloss',\n",
    "    'verbosity': 0,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a5ea3b210a216ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-30T04:48:58.318114Z",
     "start_time": "2024-03-30T04:47:07.387510Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-mlogloss:1.57664\tval-mlogloss:1.57923\n",
      "[1]\ttrain-mlogloss:1.54505\tval-mlogloss:1.54995\n",
      "[2]\ttrain-mlogloss:1.51408\tval-mlogloss:1.52172\n",
      "[3]\ttrain-mlogloss:1.48480\tval-mlogloss:1.49504\n",
      "[4]\ttrain-mlogloss:1.45733\tval-mlogloss:1.46995\n",
      "[5]\ttrain-mlogloss:1.42983\tval-mlogloss:1.44519\n",
      "[6]\ttrain-mlogloss:1.40611\tval-mlogloss:1.42421\n",
      "[7]\ttrain-mlogloss:1.38241\tval-mlogloss:1.40274\n",
      "[8]\ttrain-mlogloss:1.36141\tval-mlogloss:1.38380\n",
      "[9]\ttrain-mlogloss:1.34024\tval-mlogloss:1.36473\n",
      "[10]\ttrain-mlogloss:1.32048\tval-mlogloss:1.34721\n",
      "[11]\ttrain-mlogloss:1.30185\tval-mlogloss:1.33061\n",
      "[12]\ttrain-mlogloss:1.28266\tval-mlogloss:1.31376\n",
      "[13]\ttrain-mlogloss:1.26463\tval-mlogloss:1.29805\n",
      "[14]\ttrain-mlogloss:1.24835\tval-mlogloss:1.28376\n",
      "[15]\ttrain-mlogloss:1.23273\tval-mlogloss:1.27022\n",
      "[16]\ttrain-mlogloss:1.21609\tval-mlogloss:1.25591\n",
      "[17]\ttrain-mlogloss:1.20211\tval-mlogloss:1.24367\n",
      "[18]\ttrain-mlogloss:1.18921\tval-mlogloss:1.23272\n",
      "[19]\ttrain-mlogloss:1.17546\tval-mlogloss:1.22091\n",
      "[20]\ttrain-mlogloss:1.16154\tval-mlogloss:1.20941\n",
      "[21]\ttrain-mlogloss:1.14861\tval-mlogloss:1.19852\n",
      "[22]\ttrain-mlogloss:1.13649\tval-mlogloss:1.18825\n",
      "[23]\ttrain-mlogloss:1.12426\tval-mlogloss:1.17783\n",
      "[24]\ttrain-mlogloss:1.11319\tval-mlogloss:1.16865\n",
      "[25]\ttrain-mlogloss:1.10150\tval-mlogloss:1.15897\n",
      "[26]\ttrain-mlogloss:1.09049\tval-mlogloss:1.14979\n",
      "[27]\ttrain-mlogloss:1.08014\tval-mlogloss:1.14111\n",
      "[28]\ttrain-mlogloss:1.06946\tval-mlogloss:1.13215\n",
      "[29]\ttrain-mlogloss:1.05978\tval-mlogloss:1.12448\n",
      "[30]\ttrain-mlogloss:1.05033\tval-mlogloss:1.11688\n",
      "[31]\ttrain-mlogloss:1.04005\tval-mlogloss:1.10854\n",
      "[32]\ttrain-mlogloss:1.03110\tval-mlogloss:1.10139\n",
      "[33]\ttrain-mlogloss:1.02238\tval-mlogloss:1.09450\n",
      "[34]\ttrain-mlogloss:1.01417\tval-mlogloss:1.08804\n",
      "[35]\ttrain-mlogloss:1.00579\tval-mlogloss:1.08145\n",
      "[36]\ttrain-mlogloss:0.99795\tval-mlogloss:1.07526\n",
      "[37]\ttrain-mlogloss:0.99007\tval-mlogloss:1.06901\n",
      "[38]\ttrain-mlogloss:0.98204\tval-mlogloss:1.06263\n",
      "[39]\ttrain-mlogloss:0.97392\tval-mlogloss:1.05640\n",
      "[40]\ttrain-mlogloss:0.96653\tval-mlogloss:1.05107\n",
      "[41]\ttrain-mlogloss:0.95951\tval-mlogloss:1.04568\n",
      "[42]\ttrain-mlogloss:0.95252\tval-mlogloss:1.04031\n",
      "[43]\ttrain-mlogloss:0.94558\tval-mlogloss:1.03520\n",
      "[44]\ttrain-mlogloss:0.93923\tval-mlogloss:1.03048\n",
      "[45]\ttrain-mlogloss:0.93321\tval-mlogloss:1.02630\n",
      "[46]\ttrain-mlogloss:0.92693\tval-mlogloss:1.02147\n",
      "[47]\ttrain-mlogloss:0.92089\tval-mlogloss:1.01720\n",
      "[48]\ttrain-mlogloss:0.91485\tval-mlogloss:1.01293\n",
      "[49]\ttrain-mlogloss:0.90894\tval-mlogloss:1.00866\n",
      "[50]\ttrain-mlogloss:0.90344\tval-mlogloss:1.00480\n",
      "[51]\ttrain-mlogloss:0.89829\tval-mlogloss:1.00137\n",
      "[52]\ttrain-mlogloss:0.89253\tval-mlogloss:0.99739\n",
      "[53]\ttrain-mlogloss:0.88735\tval-mlogloss:0.99378\n",
      "[54]\ttrain-mlogloss:0.88155\tval-mlogloss:0.99000\n",
      "[55]\ttrain-mlogloss:0.87643\tval-mlogloss:0.98656\n",
      "[56]\ttrain-mlogloss:0.87163\tval-mlogloss:0.98324\n",
      "[57]\ttrain-mlogloss:0.86731\tval-mlogloss:0.98031\n",
      "[58]\ttrain-mlogloss:0.86320\tval-mlogloss:0.97752\n",
      "[59]\ttrain-mlogloss:0.85876\tval-mlogloss:0.97466\n",
      "[60]\ttrain-mlogloss:0.85395\tval-mlogloss:0.97154\n",
      "[61]\ttrain-mlogloss:0.84925\tval-mlogloss:0.96843\n",
      "[62]\ttrain-mlogloss:0.84494\tval-mlogloss:0.96573\n",
      "[63]\ttrain-mlogloss:0.84087\tval-mlogloss:0.96322\n",
      "[64]\ttrain-mlogloss:0.83647\tval-mlogloss:0.96048\n",
      "[65]\ttrain-mlogloss:0.83247\tval-mlogloss:0.95809\n",
      "[66]\ttrain-mlogloss:0.82840\tval-mlogloss:0.95552\n",
      "[67]\ttrain-mlogloss:0.82484\tval-mlogloss:0.95344\n",
      "[68]\ttrain-mlogloss:0.82080\tval-mlogloss:0.95093\n",
      "[69]\ttrain-mlogloss:0.81687\tval-mlogloss:0.94867\n",
      "[70]\ttrain-mlogloss:0.81297\tval-mlogloss:0.94637\n",
      "[71]\ttrain-mlogloss:0.80925\tval-mlogloss:0.94424\n",
      "[72]\ttrain-mlogloss:0.80557\tval-mlogloss:0.94194\n",
      "[73]\ttrain-mlogloss:0.80203\tval-mlogloss:0.93980\n",
      "[74]\ttrain-mlogloss:0.79905\tval-mlogloss:0.93798\n",
      "[75]\ttrain-mlogloss:0.79529\tval-mlogloss:0.93580\n",
      "[76]\ttrain-mlogloss:0.79196\tval-mlogloss:0.93403\n",
      "[77]\ttrain-mlogloss:0.78852\tval-mlogloss:0.93218\n",
      "[78]\ttrain-mlogloss:0.78515\tval-mlogloss:0.93034\n",
      "[79]\ttrain-mlogloss:0.78193\tval-mlogloss:0.92866\n",
      "[80]\ttrain-mlogloss:0.77898\tval-mlogloss:0.92707\n",
      "[81]\ttrain-mlogloss:0.77579\tval-mlogloss:0.92536\n",
      "[82]\ttrain-mlogloss:0.77267\tval-mlogloss:0.92391\n",
      "[83]\ttrain-mlogloss:0.76958\tval-mlogloss:0.92221\n",
      "[84]\ttrain-mlogloss:0.76656\tval-mlogloss:0.92067\n",
      "[85]\ttrain-mlogloss:0.76380\tval-mlogloss:0.91930\n",
      "[86]\ttrain-mlogloss:0.76101\tval-mlogloss:0.91791\n",
      "[87]\ttrain-mlogloss:0.75818\tval-mlogloss:0.91642\n",
      "[88]\ttrain-mlogloss:0.75517\tval-mlogloss:0.91481\n",
      "[89]\ttrain-mlogloss:0.75260\tval-mlogloss:0.91359\n",
      "[90]\ttrain-mlogloss:0.75020\tval-mlogloss:0.91236\n",
      "[91]\ttrain-mlogloss:0.74750\tval-mlogloss:0.91105\n",
      "[92]\ttrain-mlogloss:0.74505\tval-mlogloss:0.90968\n",
      "[93]\ttrain-mlogloss:0.74224\tval-mlogloss:0.90843\n",
      "[94]\ttrain-mlogloss:0.73983\tval-mlogloss:0.90729\n",
      "[95]\ttrain-mlogloss:0.73730\tval-mlogloss:0.90595\n",
      "[96]\ttrain-mlogloss:0.73485\tval-mlogloss:0.90494\n",
      "[97]\ttrain-mlogloss:0.73249\tval-mlogloss:0.90379\n",
      "[98]\ttrain-mlogloss:0.72989\tval-mlogloss:0.90251\n",
      "[99]\ttrain-mlogloss:0.72755\tval-mlogloss:0.90150\n",
      "[100]\ttrain-mlogloss:0.72501\tval-mlogloss:0.90067\n",
      "[101]\ttrain-mlogloss:0.72242\tval-mlogloss:0.89960\n",
      "[102]\ttrain-mlogloss:0.72037\tval-mlogloss:0.89870\n",
      "[103]\ttrain-mlogloss:0.71828\tval-mlogloss:0.89775\n",
      "[104]\ttrain-mlogloss:0.71627\tval-mlogloss:0.89690\n",
      "[105]\ttrain-mlogloss:0.71376\tval-mlogloss:0.89587\n",
      "[106]\ttrain-mlogloss:0.71170\tval-mlogloss:0.89502\n",
      "[107]\ttrain-mlogloss:0.70958\tval-mlogloss:0.89433\n",
      "[108]\ttrain-mlogloss:0.70753\tval-mlogloss:0.89357\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m dval \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mDMatrix(X_val, label\u001b[38;5;241m=\u001b[39my_val)\n\u001b[0;32m     34\u001b[0m evals_result \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m---> 35\u001b[0m bst \u001b[38;5;241m=\u001b[39m \u001b[43mxgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbest_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mdval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[43m                \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# Evaluate and print the final training and validation loss\u001b[39;00m\n\u001b[0;32m     39\u001b[0m train_last_eval \u001b[38;5;241m=\u001b[39m evals_result[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:730\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    729\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 730\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\training.py:181\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 181\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\xgboost\\core.py:2051\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2047\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2049\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2050\u001b[0m     _check_call(\n\u001b[1;32m-> 2051\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2052\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2053\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2054\u001b[0m     )\n\u001b[0;32m   2055\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2056\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "evals_result = {}\n",
    "bst = xgb.train(best_params, dtrain, num_boost_round=1000, evals=[(dtrain, 'train'), (dval, 'val')],\n",
    "                early_stopping_rounds=10, evals_result=evals_result, verbose_eval=True)\n",
    "\n",
    "# Evaluate and print the final training and validation loss\n",
    "train_last_eval = evals_result['train']['mlogloss'][-1]\n",
    "val_last_eval = evals_result['val']['mlogloss'][-1]\n",
    "\n",
    "print(f\"Training Multiclass Logarithmic Loss: {train_last_eval}\")\n",
    "print(f\"Validation Multiclass Logarithmic Loss: {val_last_eval}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1527521c5801211",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Generate Submission csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1893712801ef4bae",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-03-30T04:50:01.437762Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tfull-mlogloss:1.57695\n",
      "[1]\tfull-mlogloss:1.54542\n",
      "[2]\tfull-mlogloss:1.51453\n",
      "[3]\tfull-mlogloss:1.48548\n",
      "[4]\tfull-mlogloss:1.45824\n",
      "[5]\tfull-mlogloss:1.43111\n",
      "[6]\tfull-mlogloss:1.40788\n",
      "[7]\tfull-mlogloss:1.38428\n",
      "[8]\tfull-mlogloss:1.36341\n",
      "[9]\tfull-mlogloss:1.34247\n",
      "[10]\tfull-mlogloss:1.32303\n",
      "[11]\tfull-mlogloss:1.30470\n",
      "[12]\tfull-mlogloss:1.28606\n",
      "[13]\tfull-mlogloss:1.26843\n",
      "[14]\tfull-mlogloss:1.25261\n",
      "[15]\tfull-mlogloss:1.23731\n",
      "[16]\tfull-mlogloss:1.22121\n",
      "[17]\tfull-mlogloss:1.20753\n",
      "[18]\tfull-mlogloss:1.19477\n",
      "[19]\tfull-mlogloss:1.18131\n",
      "[20]\tfull-mlogloss:1.16787\n",
      "[21]\tfull-mlogloss:1.15534\n",
      "[22]\tfull-mlogloss:1.14366\n",
      "[23]\tfull-mlogloss:1.13168\n",
      "[24]\tfull-mlogloss:1.12100\n",
      "[25]\tfull-mlogloss:1.10952\n",
      "[26]\tfull-mlogloss:1.09881\n",
      "[27]\tfull-mlogloss:1.08881\n",
      "[28]\tfull-mlogloss:1.07847\n",
      "[29]\tfull-mlogloss:1.06910\n",
      "[30]\tfull-mlogloss:1.05987\n",
      "[31]\tfull-mlogloss:1.04993\n",
      "[32]\tfull-mlogloss:1.04138\n",
      "[33]\tfull-mlogloss:1.03302\n",
      "[34]\tfull-mlogloss:1.02526\n",
      "[35]\tfull-mlogloss:1.01700\n",
      "[36]\tfull-mlogloss:1.00962\n",
      "[37]\tfull-mlogloss:1.00197\n",
      "[38]\tfull-mlogloss:0.99427\n",
      "[39]\tfull-mlogloss:0.98665\n",
      "[40]\tfull-mlogloss:0.97968\n",
      "[41]\tfull-mlogloss:0.97283\n",
      "[42]\tfull-mlogloss:0.96614\n",
      "[43]\tfull-mlogloss:0.95950\n",
      "[44]\tfull-mlogloss:0.95348\n",
      "[45]\tfull-mlogloss:0.94776\n",
      "[46]\tfull-mlogloss:0.94172\n",
      "[47]\tfull-mlogloss:0.93595\n",
      "[48]\tfull-mlogloss:0.93019\n",
      "[49]\tfull-mlogloss:0.92457\n",
      "[50]\tfull-mlogloss:0.91934\n",
      "[51]\tfull-mlogloss:0.91448\n",
      "[52]\tfull-mlogloss:0.90936\n",
      "[53]\tfull-mlogloss:0.90439\n",
      "[54]\tfull-mlogloss:0.89896\n",
      "[55]\tfull-mlogloss:0.89428\n",
      "[56]\tfull-mlogloss:0.88941\n",
      "[57]\tfull-mlogloss:0.88532\n",
      "[58]\tfull-mlogloss:0.88120\n",
      "[59]\tfull-mlogloss:0.87702\n",
      "[60]\tfull-mlogloss:0.87243\n",
      "[61]\tfull-mlogloss:0.86804\n",
      "[62]\tfull-mlogloss:0.86400\n",
      "[63]\tfull-mlogloss:0.86022\n",
      "[64]\tfull-mlogloss:0.85621\n",
      "[65]\tfull-mlogloss:0.85253\n",
      "[66]\tfull-mlogloss:0.84865\n",
      "[67]\tfull-mlogloss:0.84542\n",
      "[68]\tfull-mlogloss:0.84153\n",
      "[69]\tfull-mlogloss:0.83788\n",
      "[70]\tfull-mlogloss:0.83422\n",
      "[71]\tfull-mlogloss:0.83074\n",
      "[72]\tfull-mlogloss:0.82713\n",
      "[73]\tfull-mlogloss:0.82387\n",
      "[74]\tfull-mlogloss:0.82087\n",
      "[75]\tfull-mlogloss:0.81744\n",
      "[76]\tfull-mlogloss:0.81429\n",
      "[77]\tfull-mlogloss:0.81120\n",
      "[78]\tfull-mlogloss:0.80814\n",
      "[79]\tfull-mlogloss:0.80515\n",
      "[80]\tfull-mlogloss:0.80237\n",
      "[81]\tfull-mlogloss:0.79941\n",
      "[82]\tfull-mlogloss:0.79671\n",
      "[83]\tfull-mlogloss:0.79380\n",
      "[84]\tfull-mlogloss:0.79104\n",
      "[85]\tfull-mlogloss:0.78838\n",
      "[86]\tfull-mlogloss:0.78581\n",
      "[87]\tfull-mlogloss:0.78321\n",
      "[88]\tfull-mlogloss:0.78041\n",
      "[89]\tfull-mlogloss:0.77804\n",
      "[90]\tfull-mlogloss:0.77569\n",
      "[91]\tfull-mlogloss:0.77320\n",
      "[92]\tfull-mlogloss:0.77087\n",
      "[93]\tfull-mlogloss:0.76841\n",
      "[94]\tfull-mlogloss:0.76628\n",
      "[95]\tfull-mlogloss:0.76380\n",
      "[96]\tfull-mlogloss:0.76137\n",
      "[97]\tfull-mlogloss:0.75896\n",
      "[98]\tfull-mlogloss:0.75648\n",
      "[99]\tfull-mlogloss:0.75433\n",
      "[100]\tfull-mlogloss:0.75210\n",
      "[101]\tfull-mlogloss:0.74961\n",
      "[102]\tfull-mlogloss:0.74769\n",
      "[103]\tfull-mlogloss:0.74576\n",
      "[104]\tfull-mlogloss:0.74387\n",
      "[105]\tfull-mlogloss:0.74159\n",
      "[106]\tfull-mlogloss:0.73947\n",
      "[107]\tfull-mlogloss:0.73747\n",
      "[108]\tfull-mlogloss:0.73555\n",
      "[109]\tfull-mlogloss:0.73368\n",
      "[110]\tfull-mlogloss:0.73171\n",
      "[111]\tfull-mlogloss:0.73001\n",
      "[112]\tfull-mlogloss:0.72818\n",
      "[113]\tfull-mlogloss:0.72625\n",
      "[114]\tfull-mlogloss:0.72455\n",
      "[115]\tfull-mlogloss:0.72269\n",
      "[116]\tfull-mlogloss:0.72076\n",
      "[117]\tfull-mlogloss:0.71895\n",
      "[118]\tfull-mlogloss:0.71714\n",
      "[119]\tfull-mlogloss:0.71533\n",
      "[120]\tfull-mlogloss:0.71363\n",
      "[121]\tfull-mlogloss:0.71183\n",
      "[122]\tfull-mlogloss:0.71024\n",
      "[123]\tfull-mlogloss:0.70876\n",
      "[124]\tfull-mlogloss:0.70724\n",
      "[125]\tfull-mlogloss:0.70565\n",
      "[126]\tfull-mlogloss:0.70395\n",
      "[127]\tfull-mlogloss:0.70243\n",
      "[128]\tfull-mlogloss:0.70105\n",
      "[129]\tfull-mlogloss:0.69937\n",
      "[130]\tfull-mlogloss:0.69771\n",
      "[131]\tfull-mlogloss:0.69610\n",
      "[132]\tfull-mlogloss:0.69452\n",
      "[133]\tfull-mlogloss:0.69303\n",
      "[134]\tfull-mlogloss:0.69141\n",
      "[135]\tfull-mlogloss:0.69004\n",
      "[136]\tfull-mlogloss:0.68876\n",
      "[137]\tfull-mlogloss:0.68715\n",
      "[138]\tfull-mlogloss:0.68569\n",
      "[139]\tfull-mlogloss:0.68417\n",
      "[140]\tfull-mlogloss:0.68290\n",
      "[141]\tfull-mlogloss:0.68141\n",
      "[142]\tfull-mlogloss:0.68011\n",
      "[143]\tfull-mlogloss:0.67876\n",
      "[144]\tfull-mlogloss:0.67739\n",
      "[145]\tfull-mlogloss:0.67600\n",
      "[146]\tfull-mlogloss:0.67468\n",
      "[147]\tfull-mlogloss:0.67349\n",
      "[148]\tfull-mlogloss:0.67206\n",
      "[149]\tfull-mlogloss:0.67073\n",
      "[150]\tfull-mlogloss:0.66951\n",
      "[151]\tfull-mlogloss:0.66806\n",
      "[152]\tfull-mlogloss:0.66681\n",
      "[153]\tfull-mlogloss:0.66557\n",
      "[154]\tfull-mlogloss:0.66432\n",
      "[155]\tfull-mlogloss:0.66313\n",
      "[156]\tfull-mlogloss:0.66191\n",
      "[157]\tfull-mlogloss:0.66049\n",
      "[158]\tfull-mlogloss:0.65922\n",
      "[159]\tfull-mlogloss:0.65829\n",
      "[160]\tfull-mlogloss:0.65728\n",
      "[161]\tfull-mlogloss:0.65608\n",
      "[162]\tfull-mlogloss:0.65476\n",
      "[163]\tfull-mlogloss:0.65339\n",
      "[164]\tfull-mlogloss:0.65237\n",
      "[165]\tfull-mlogloss:0.65104\n",
      "[166]\tfull-mlogloss:0.64985\n",
      "[167]\tfull-mlogloss:0.64862\n",
      "[168]\tfull-mlogloss:0.64727\n",
      "[169]\tfull-mlogloss:0.64606\n",
      "[170]\tfull-mlogloss:0.64516\n",
      "[171]\tfull-mlogloss:0.64418\n",
      "[172]\tfull-mlogloss:0.64299\n",
      "[173]\tfull-mlogloss:0.64198\n",
      "[174]\tfull-mlogloss:0.64059\n",
      "[175]\tfull-mlogloss:0.63931\n",
      "[176]\tfull-mlogloss:0.63810\n",
      "[177]\tfull-mlogloss:0.63670\n",
      "[178]\tfull-mlogloss:0.63578\n",
      "[179]\tfull-mlogloss:0.63449\n",
      "[180]\tfull-mlogloss:0.63346\n",
      "[181]\tfull-mlogloss:0.63251\n",
      "[182]\tfull-mlogloss:0.63157\n",
      "[183]\tfull-mlogloss:0.63046\n",
      "[184]\tfull-mlogloss:0.62924\n",
      "[185]\tfull-mlogloss:0.62818\n",
      "[186]\tfull-mlogloss:0.62700\n",
      "[187]\tfull-mlogloss:0.62601\n",
      "[188]\tfull-mlogloss:0.62504\n",
      "[189]\tfull-mlogloss:0.62403\n",
      "[190]\tfull-mlogloss:0.62301\n",
      "[191]\tfull-mlogloss:0.62175\n",
      "[192]\tfull-mlogloss:0.62074\n",
      "[193]\tfull-mlogloss:0.61951\n",
      "[194]\tfull-mlogloss:0.61859\n",
      "[195]\tfull-mlogloss:0.61767\n",
      "[196]\tfull-mlogloss:0.61679\n",
      "[197]\tfull-mlogloss:0.61562\n",
      "[198]\tfull-mlogloss:0.61452\n",
      "[199]\tfull-mlogloss:0.61341\n",
      "[200]\tfull-mlogloss:0.61231\n",
      "[201]\tfull-mlogloss:0.61125\n",
      "[202]\tfull-mlogloss:0.61019\n",
      "[203]\tfull-mlogloss:0.60918\n",
      "[204]\tfull-mlogloss:0.60807\n",
      "[205]\tfull-mlogloss:0.60705\n",
      "[206]\tfull-mlogloss:0.60619\n",
      "[207]\tfull-mlogloss:0.60537\n",
      "[208]\tfull-mlogloss:0.60429\n",
      "[209]\tfull-mlogloss:0.60347\n",
      "[210]\tfull-mlogloss:0.60269\n",
      "[211]\tfull-mlogloss:0.60162\n",
      "[212]\tfull-mlogloss:0.60073\n",
      "[213]\tfull-mlogloss:0.59999\n",
      "[214]\tfull-mlogloss:0.59928\n",
      "[215]\tfull-mlogloss:0.59830\n",
      "[216]\tfull-mlogloss:0.59737\n",
      "[217]\tfull-mlogloss:0.59651\n",
      "[218]\tfull-mlogloss:0.59572\n",
      "[219]\tfull-mlogloss:0.59481\n",
      "[220]\tfull-mlogloss:0.59399\n",
      "[221]\tfull-mlogloss:0.59325\n",
      "[222]\tfull-mlogloss:0.59252\n",
      "[223]\tfull-mlogloss:0.59143\n",
      "[224]\tfull-mlogloss:0.59063\n",
      "[225]\tfull-mlogloss:0.58975\n",
      "[226]\tfull-mlogloss:0.58883\n",
      "[227]\tfull-mlogloss:0.58813\n",
      "[228]\tfull-mlogloss:0.58749\n",
      "[229]\tfull-mlogloss:0.58655\n",
      "[230]\tfull-mlogloss:0.58587\n",
      "[231]\tfull-mlogloss:0.58499\n",
      "[232]\tfull-mlogloss:0.58428\n",
      "[233]\tfull-mlogloss:0.58346\n",
      "[234]\tfull-mlogloss:0.58245\n",
      "[235]\tfull-mlogloss:0.58154\n",
      "[236]\tfull-mlogloss:0.58078\n",
      "[237]\tfull-mlogloss:0.57995\n",
      "[238]\tfull-mlogloss:0.57909\n",
      "[239]\tfull-mlogloss:0.57813\n",
      "[240]\tfull-mlogloss:0.57729\n",
      "[241]\tfull-mlogloss:0.57633\n",
      "[242]\tfull-mlogloss:0.57571\n",
      "[243]\tfull-mlogloss:0.57489\n",
      "[244]\tfull-mlogloss:0.57389\n",
      "[245]\tfull-mlogloss:0.57313\n",
      "[246]\tfull-mlogloss:0.57220\n",
      "[247]\tfull-mlogloss:0.57130\n",
      "[248]\tfull-mlogloss:0.57045\n",
      "[249]\tfull-mlogloss:0.56947\n",
      "[250]\tfull-mlogloss:0.56852\n",
      "[251]\tfull-mlogloss:0.56753\n",
      "[252]\tfull-mlogloss:0.56689\n",
      "[253]\tfull-mlogloss:0.56623\n",
      "[254]\tfull-mlogloss:0.56570\n",
      "[255]\tfull-mlogloss:0.56503\n",
      "[256]\tfull-mlogloss:0.56435\n",
      "[257]\tfull-mlogloss:0.56329\n",
      "[258]\tfull-mlogloss:0.56280\n",
      "[259]\tfull-mlogloss:0.56201\n",
      "[260]\tfull-mlogloss:0.56129\n",
      "[261]\tfull-mlogloss:0.56089\n",
      "[262]\tfull-mlogloss:0.56008\n",
      "[263]\tfull-mlogloss:0.55945\n",
      "[264]\tfull-mlogloss:0.55857\n",
      "[265]\tfull-mlogloss:0.55797\n",
      "[266]\tfull-mlogloss:0.55728\n",
      "[267]\tfull-mlogloss:0.55679\n",
      "[268]\tfull-mlogloss:0.55607\n",
      "[269]\tfull-mlogloss:0.55554\n",
      "[270]\tfull-mlogloss:0.55479\n",
      "[271]\tfull-mlogloss:0.55410\n",
      "[272]\tfull-mlogloss:0.55339\n",
      "[273]\tfull-mlogloss:0.55275\n",
      "[274]\tfull-mlogloss:0.55232\n",
      "[275]\tfull-mlogloss:0.55147\n",
      "[276]\tfull-mlogloss:0.55077\n",
      "[277]\tfull-mlogloss:0.54996\n",
      "[278]\tfull-mlogloss:0.54911\n",
      "[279]\tfull-mlogloss:0.54833\n",
      "[280]\tfull-mlogloss:0.54761\n",
      "[281]\tfull-mlogloss:0.54702\n",
      "[282]\tfull-mlogloss:0.54651\n",
      "[283]\tfull-mlogloss:0.54604\n",
      "[284]\tfull-mlogloss:0.54529\n",
      "[285]\tfull-mlogloss:0.54474\n",
      "[286]\tfull-mlogloss:0.54419\n",
      "[287]\tfull-mlogloss:0.54368\n",
      "[288]\tfull-mlogloss:0.54322\n",
      "[289]\tfull-mlogloss:0.54266\n",
      "[290]\tfull-mlogloss:0.54202\n",
      "[291]\tfull-mlogloss:0.54129\n",
      "[292]\tfull-mlogloss:0.54050\n",
      "[293]\tfull-mlogloss:0.53987\n",
      "[294]\tfull-mlogloss:0.53919\n",
      "[295]\tfull-mlogloss:0.53833\n",
      "[296]\tfull-mlogloss:0.53771\n",
      "[297]\tfull-mlogloss:0.53696\n",
      "[298]\tfull-mlogloss:0.53637\n",
      "[299]\tfull-mlogloss:0.53559\n",
      "[300]\tfull-mlogloss:0.53514\n",
      "[301]\tfull-mlogloss:0.53452\n",
      "[302]\tfull-mlogloss:0.53388\n",
      "[303]\tfull-mlogloss:0.53321\n",
      "[304]\tfull-mlogloss:0.53259\n",
      "[305]\tfull-mlogloss:0.53200\n",
      "[306]\tfull-mlogloss:0.53122\n",
      "[307]\tfull-mlogloss:0.53060\n",
      "[308]\tfull-mlogloss:0.53002\n",
      "[309]\tfull-mlogloss:0.52936\n",
      "[310]\tfull-mlogloss:0.52875\n",
      "[311]\tfull-mlogloss:0.52824\n",
      "[312]\tfull-mlogloss:0.52787\n",
      "[313]\tfull-mlogloss:0.52716\n",
      "[314]\tfull-mlogloss:0.52655\n",
      "[315]\tfull-mlogloss:0.52585\n",
      "[316]\tfull-mlogloss:0.52512\n",
      "[317]\tfull-mlogloss:0.52434\n",
      "[318]\tfull-mlogloss:0.52396\n",
      "[319]\tfull-mlogloss:0.52335\n",
      "[320]\tfull-mlogloss:0.52278\n",
      "[321]\tfull-mlogloss:0.52217\n",
      "[322]\tfull-mlogloss:0.52153\n",
      "[323]\tfull-mlogloss:0.52092\n",
      "[324]\tfull-mlogloss:0.52059\n",
      "[325]\tfull-mlogloss:0.51986\n",
      "[326]\tfull-mlogloss:0.51931\n",
      "[327]\tfull-mlogloss:0.51865\n",
      "[328]\tfull-mlogloss:0.51807\n",
      "[329]\tfull-mlogloss:0.51741\n",
      "[330]\tfull-mlogloss:0.51684\n",
      "[331]\tfull-mlogloss:0.51606\n",
      "[332]\tfull-mlogloss:0.51563\n",
      "[333]\tfull-mlogloss:0.51514\n",
      "[334]\tfull-mlogloss:0.51447\n",
      "[335]\tfull-mlogloss:0.51395\n",
      "[336]\tfull-mlogloss:0.51351\n",
      "[337]\tfull-mlogloss:0.51271\n",
      "[338]\tfull-mlogloss:0.51217\n",
      "[339]\tfull-mlogloss:0.51175\n",
      "[340]\tfull-mlogloss:0.51118\n",
      "[341]\tfull-mlogloss:0.51069\n",
      "[342]\tfull-mlogloss:0.50995\n",
      "[343]\tfull-mlogloss:0.50920\n",
      "[344]\tfull-mlogloss:0.50846\n",
      "[345]\tfull-mlogloss:0.50769\n",
      "[346]\tfull-mlogloss:0.50729\n",
      "[347]\tfull-mlogloss:0.50666\n",
      "[348]\tfull-mlogloss:0.50606\n",
      "[349]\tfull-mlogloss:0.50547\n",
      "[350]\tfull-mlogloss:0.50495\n",
      "[351]\tfull-mlogloss:0.50452\n",
      "[352]\tfull-mlogloss:0.50419\n",
      "[353]\tfull-mlogloss:0.50380\n",
      "[354]\tfull-mlogloss:0.50298\n",
      "[355]\tfull-mlogloss:0.50259\n",
      "[356]\tfull-mlogloss:0.50185\n",
      "[357]\tfull-mlogloss:0.50129\n",
      "[358]\tfull-mlogloss:0.50063\n",
      "[359]\tfull-mlogloss:0.50017\n",
      "[360]\tfull-mlogloss:0.49979\n",
      "[361]\tfull-mlogloss:0.49939\n",
      "[362]\tfull-mlogloss:0.49886\n",
      "[363]\tfull-mlogloss:0.49853\n",
      "[364]\tfull-mlogloss:0.49800\n",
      "[365]\tfull-mlogloss:0.49762\n",
      "[366]\tfull-mlogloss:0.49711\n",
      "[367]\tfull-mlogloss:0.49656\n",
      "[368]\tfull-mlogloss:0.49610\n",
      "[369]\tfull-mlogloss:0.49562\n",
      "[370]\tfull-mlogloss:0.49510\n",
      "[371]\tfull-mlogloss:0.49447\n",
      "[372]\tfull-mlogloss:0.49387\n",
      "[373]\tfull-mlogloss:0.49341\n",
      "[374]\tfull-mlogloss:0.49294\n",
      "[375]\tfull-mlogloss:0.49239\n",
      "[376]\tfull-mlogloss:0.49188\n",
      "[377]\tfull-mlogloss:0.49121\n",
      "[378]\tfull-mlogloss:0.49066\n",
      "[379]\tfull-mlogloss:0.49018\n",
      "[380]\tfull-mlogloss:0.48969\n",
      "[381]\tfull-mlogloss:0.48898\n",
      "[382]\tfull-mlogloss:0.48863\n",
      "[383]\tfull-mlogloss:0.48821\n",
      "[384]\tfull-mlogloss:0.48777\n",
      "[385]\tfull-mlogloss:0.48737\n",
      "[386]\tfull-mlogloss:0.48696\n",
      "[387]\tfull-mlogloss:0.48640\n",
      "[388]\tfull-mlogloss:0.48591\n",
      "[389]\tfull-mlogloss:0.48535\n",
      "[390]\tfull-mlogloss:0.48470\n",
      "[391]\tfull-mlogloss:0.48424\n",
      "[392]\tfull-mlogloss:0.48368\n",
      "[393]\tfull-mlogloss:0.48323\n",
      "[394]\tfull-mlogloss:0.48272\n",
      "[395]\tfull-mlogloss:0.48218\n",
      "[396]\tfull-mlogloss:0.48163\n",
      "[397]\tfull-mlogloss:0.48126\n",
      "[398]\tfull-mlogloss:0.48084\n",
      "[399]\tfull-mlogloss:0.48033\n",
      "[400]\tfull-mlogloss:0.47985\n",
      "[401]\tfull-mlogloss:0.47928\n",
      "[402]\tfull-mlogloss:0.47870\n",
      "[403]\tfull-mlogloss:0.47833\n",
      "[404]\tfull-mlogloss:0.47791\n",
      "[405]\tfull-mlogloss:0.47737\n",
      "[406]\tfull-mlogloss:0.47710\n",
      "[407]\tfull-mlogloss:0.47663\n",
      "[408]\tfull-mlogloss:0.47616\n",
      "[409]\tfull-mlogloss:0.47579\n",
      "[410]\tfull-mlogloss:0.47554\n",
      "[411]\tfull-mlogloss:0.47503\n",
      "[412]\tfull-mlogloss:0.47451\n",
      "[413]\tfull-mlogloss:0.47407\n",
      "[414]\tfull-mlogloss:0.47345\n",
      "[415]\tfull-mlogloss:0.47299\n",
      "[416]\tfull-mlogloss:0.47242\n",
      "[417]\tfull-mlogloss:0.47205\n",
      "[418]\tfull-mlogloss:0.47152\n",
      "[419]\tfull-mlogloss:0.47096\n",
      "[420]\tfull-mlogloss:0.47049\n",
      "[421]\tfull-mlogloss:0.46983\n",
      "[422]\tfull-mlogloss:0.46927\n",
      "[423]\tfull-mlogloss:0.46870\n",
      "[424]\tfull-mlogloss:0.46841\n",
      "[425]\tfull-mlogloss:0.46803\n",
      "[426]\tfull-mlogloss:0.46771\n",
      "[427]\tfull-mlogloss:0.46727\n",
      "[428]\tfull-mlogloss:0.46691\n",
      "[429]\tfull-mlogloss:0.46645\n",
      "[430]\tfull-mlogloss:0.46587\n",
      "[431]\tfull-mlogloss:0.46566\n",
      "[432]\tfull-mlogloss:0.46529\n",
      "[433]\tfull-mlogloss:0.46470\n",
      "[434]\tfull-mlogloss:0.46443\n",
      "[435]\tfull-mlogloss:0.46412\n",
      "[436]\tfull-mlogloss:0.46381\n",
      "[437]\tfull-mlogloss:0.46339\n",
      "[438]\tfull-mlogloss:0.46304\n",
      "[439]\tfull-mlogloss:0.46290\n",
      "[440]\tfull-mlogloss:0.46235\n",
      "[441]\tfull-mlogloss:0.46175\n",
      "[442]\tfull-mlogloss:0.46146\n",
      "[443]\tfull-mlogloss:0.46115\n",
      "[444]\tfull-mlogloss:0.46066\n",
      "[445]\tfull-mlogloss:0.46026\n",
      "[446]\tfull-mlogloss:0.45983\n",
      "[447]\tfull-mlogloss:0.45937\n",
      "[448]\tfull-mlogloss:0.45887\n",
      "[449]\tfull-mlogloss:0.45831\n",
      "[450]\tfull-mlogloss:0.45789\n",
      "[451]\tfull-mlogloss:0.45741\n",
      "[452]\tfull-mlogloss:0.45691\n",
      "[453]\tfull-mlogloss:0.45627\n",
      "[454]\tfull-mlogloss:0.45588\n",
      "[455]\tfull-mlogloss:0.45544\n",
      "[456]\tfull-mlogloss:0.45505\n",
      "[457]\tfull-mlogloss:0.45455\n"
     ]
    }
   ],
   "source": [
    "# Combine X_train and X_val, and y_train and y_val\n",
    "X_full = pd.concat([X_train, X_val], axis=0)\n",
    "y_full = pd.concat([y_train, y_val], axis=0)\n",
    "\n",
    "dfull = xgb.DMatrix(X_full, label=y_full)\n",
    "\n",
    "# Retrain the model\n",
    "evals_result_full = {}\n",
    "bst_full = xgb.train(best_params, dfull, num_boost_round=1000, evals=[(dfull, 'full')],\n",
    "                     early_stopping_rounds=10, evals_result=evals_result_full, verbose_eval=True)\n",
    "\n",
    "train_full_last_eval = evals_result_full['full']['mlogloss'][-1]\n",
    "print(f\"Full Training Multiclass Logarithmic Loss: {train_full_last_eval}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ae6668498e2687f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-30T04:24:51.058758Z",
     "start_time": "2024-03-30T04:24:50.527135Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(df_test)\n",
    "y_test_probs = bst_full.predict(dtest)\n",
    "class_order = [0, 1, 2, 3, 4]\n",
    "class_mapping = {class_label: f\"Class{class_label}\" for class_label in class_order}\n",
    "\n",
    "submission_df = pd.DataFrame(y_test_probs, columns=class_mapping.values())\n",
    "submission_df.columns = ['no answer', 'very important', 'quite important', 'not important', 'not at all important']\n",
    "submission_df.insert(0, 'id', df_test.index)\n",
    "\n",
    "# Save the submission file\n",
    "submission_file = ('eda_script_og_amy_submission.csv')\n",
    "submission_df.to_csv(submission_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
