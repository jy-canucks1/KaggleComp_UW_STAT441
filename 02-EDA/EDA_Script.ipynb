{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "# Import packages\n",
    "import pandas as pd\n",
    "from warnings import simplefilter\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set options\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.max_columns = 999\n",
    "\n",
    "train_x_raw = pd.read_csv(\"../01-Data/X_train.csv\", low_memory = True, index_col=0)\n",
    "train_y_raw = pd.read_csv(\"../01-Data/y_train.csv\", low_memory = True, index_col=0)\n",
    "test_x_raw = pd.read_csv(\"../01-Data/X_test.csv\", low_memory=True, index_col=0)\n",
    "\n",
    "df_train = pd.DataFrame(train_x_raw)\n",
    "df_test = pd.DataFrame(test_x_raw)\n",
    "df_y = pd.DataFrame(train_y_raw)\n",
    "\n",
    "############################################################# FUNCTIONS ###############################################################\n",
    "\n",
    "### Function to find the targeted colname\n",
    "def find_colname_start(data, target):\n",
    "  temp = []\n",
    "  for varname in data.columns:\n",
    "      if varname.startwith(target):\n",
    "        temp.append(varname)\n",
    "  return(temp)\n",
    "  \n",
    "def find_colname_end(data, target):\n",
    "  temp = []\n",
    "  for varname in data.columns:\n",
    "      if varname.endswith(target):\n",
    "        temp.append(varname)\n",
    "  return(temp)\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def merge_columns(dat, colname):\n",
    "    for name in colname:\n",
    "        name_org = name.replace(\"_11c\", \"\")\n",
    "        dat.loc[dat[name_org] == -4, name_org] = dat.loc[dat[name_org] == -4, name]\n",
    "\n",
    "\n",
    "def print_diff(varname):\n",
    "  print(set(df_train[varname].unique()).difference(set(df_test[varname].unique())))\n",
    "\n",
    "def cumulatively_categorise(column,threshold=0.80,return_categories_list=True):\n",
    "  #Find the threshold value using the percentage and number of instances in the column\n",
    "  threshold_value=int(threshold*len(column))\n",
    "  #Initialise an empty list for our new minimised categories \n",
    "  categories_list=[]\n",
    "  #Initialise a variable to calculate the sum of frequencies\n",
    "  s=0\n",
    "  #Create a counter dictionary of the form unique_value: frequency\n",
    "  counts=Counter(column)\n",
    "\n",
    "  #Loop through the category name and its corresponding frequency after sorting the categories by descending order of frequency\n",
    "  for i,j in counts.most_common():\n",
    "    #Add the frequency to the global sum\n",
    "    s+=dict(counts)[i]\n",
    "    #Append the category name to the list\n",
    "    categories_list.append(i)\n",
    "    #Check if the global sum has reached the threshold value, if so break the loop\n",
    "    if s>=threshold_value:\n",
    "      break\n",
    "  #Append the category Other to the list\n",
    "  categories_list.append(-100)\n",
    "\n",
    "  #Replace all instances not in our new categories by Other  \n",
    "  new_column=column.apply(lambda x: x if x in categories_list else -100)\n",
    "\n",
    "  #Return transformed column and unique values if return_categories=True\n",
    "  if(return_categories_list):\n",
    "    return new_column,categories_list\n",
    "  #Return only the transformed column if return_categories=False\n",
    "  else:\n",
    "    return new_column\n",
    "  \n",
    "def simpleAggregation_helper(var, threshold):\n",
    "  train=df_train[var]\n",
    "  test=df_test[var]\n",
    "  cat = [train, test]\n",
    "  df = pd.concat(cat)\n",
    "  transformed_column=cumulatively_categorise(df, threshold, return_categories_list=False)\n",
    "  tc_train=transformed_column[0:len(train)]\n",
    "  tc_test=transformed_column[len(train):len(train)+len(test)]\n",
    "  df_train[var]=tc_train\n",
    "  df_test[var]=tc_test\n",
    "\n",
    "  \n",
    "def simpleAggregation(variable, threshold=0.8):\n",
    "    if isinstance(variable, str):\n",
    "      simpleAggregation_helper(variable, threshold)\n",
    "    elif isinstance(variable, list):\n",
    "      for varname in variable:\n",
    "        simpleAggregation_helper(varname, threshold)\n",
    "        \n",
    "### Convert fw_start ==> Start month of fw\n",
    "### Convert fw_end ==> Duration of fw\n",
    "def timeEDA(data):\n",
    "    fw_start = data['fw_start']\n",
    "    fw_end = data['fw_end']\n",
    "    fieldwork_start_month = []\n",
    "    fw_duration = []\n",
    "    for obs in range(0, len(fw_end)):\n",
    "        fw_start_year = int(str(fw_start[obs])[0:4])\n",
    "        fw_start_month = int(str(fw_start[obs])[4:6])\n",
    "        fw_end_year = int(str(fw_end[obs])[0:4])\n",
    "        fw_end_month = int(str(fw_end[obs])[4:6])\n",
    "        duration_year = fw_end_year - fw_start_year\n",
    "        duration_month = fw_end_month - fw_start_month\n",
    "        duration = 12*duration_year + duration_month\n",
    "        fieldwork_start_month.append(fw_start_month)\n",
    "        fw_duration.append(duration)\n",
    "    data['fw_start'] = fieldwork_start_month\n",
    "    data['fw_end'] = fw_duration\n",
    "    data.rename(columns={'fw_start':'fw_start_month', 'fw_end':'fw_duration'}, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "################################################################### GLOBAL VAR ###########################################################\n",
    "columns_to_encode = []\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################################################### INITIAL DROP / MISSING DATA PREPROCESSING #################################################\n",
    "\n",
    "columns_to_drop = ['c_abrv', 'f46_IT', 'v72_DE', 'v73_DE', 'v74_DE', 'v75_DE', 'v76_DE', 'v77_DE', 'v78_DE', 'v79_DE']\n",
    "columns_to_drop += ['f252_edulvlb_CH']\n",
    "df_train.drop(columns=columns_to_drop, inplace=True)\n",
    "df_test.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "#columns_to_drop = ['v228b', 'v231b', 'v233b', 'v251b', 'f252_edulvlb_CH', 'v275b_N1', 'v275b_N2', 'v275c_N2', 'v281a']\n",
    "\n",
    "# Imputation \n",
    "df_train.fillna({'v231b_r': -3}, inplace=True)\n",
    "df_test.fillna({'v231b_r': -3}, inplace=True)\n",
    "\n",
    "df_train.fillna({'v233b_r': -3}, inplace=True)\n",
    "df_test.fillna({'v233b_r': -3}, inplace=True)\n",
    "\n",
    "df_train.fillna({'v251b_r': -3}, inplace=True)\n",
    "df_test.fillna({'v251b_r': -3}, inplace=True)\n",
    "\n",
    "df_train.fillna({'v228b_r': -3}, inplace=True)\n",
    "df_test.fillna({'v228b_r': -3}, inplace=True)\n",
    "\n",
    "\n",
    "####################################################### Age-related variables processing #############################################\n",
    "# v226 : respondent age year\n",
    "# age age:respondent\n",
    "# age_r age recorded (6 intervals)\n",
    "# age_r2 age recoded (3 intervals)\n",
    "# age_r3 age recoded (7 intervals)\n",
    "## Keep age_r3\n",
    "ages_to_drop = ['v226', 'age', 'age_r', 'age_r2']\n",
    "df_train.drop(columns=ages_to_drop, inplace=True)\n",
    "df_test.drop(columns=ages_to_drop, inplace=True)\n",
    "# DECIDE WHICH ONE TO KEEP AFTER EVALUATING \n",
    "\n",
    "############################################################################### HOUSEHOLD / SPOUSE ######################################################################\n",
    "\n",
    "#################################### Education level-related variables drop ####################################\n",
    "# v243*: educational level respondent: ... with variations\n",
    "# keep v243_ISCED_3: educational level respondent: ISCED-code three digit  \n",
    "v243_to_drop = ['v243_edulvlb', 'v243_edulvlb_2', 'v243_edulvlb_1', 'v243_ISCED_2', 'v243_ISCED_2b','v243_ISCED_1', 'v243_EISCED', \n",
    "                'v243_ISCED97', 'v243_8cat', 'v243_r', 'v243_cs', 'v243_cs_DE1', 'v243_cs_DE2', 'v243_cs_DE3', 'v243_cs_GB1', 'v243_cs_GB2']\n",
    "df_train.drop(columns=v243_to_drop, inplace=True)\n",
    "df_test.drop(columns=v243_to_drop, inplace=True)\n",
    "\n",
    "# ### Job kinds-related variables drop\n",
    "### keep v246_ESeC : kind of job respondent\n",
    "v246_to_drop = ['v246_ISCO_2', 'v246_SIOPS', 'v246_ISEI', 'v246_egp']\n",
    "df_train.drop(columns=v246_to_drop, inplace=True)\n",
    "df_test.drop(columns=v246_to_drop, inplace=True)\n",
    "\n",
    "\n",
    "# ### Partner Education Level variables drop\n",
    "# keep v252_cs : educational level spouse/partner:\n",
    "v252_to_drop = ['v252_edulvlb', 'v252_edulvlb_1', 'v252_ISCED_3', 'v252_ISCED_2', 'v252_ISCED_2b', 'v252_ISCED_1', 'v252_EISCED', 'v252_ISCED97', \n",
    "                'v252_8cat', 'v252_r', 'v252_edulvlb_2', 'v252_cs_DE1', 'v252_cs_DE2', 'v252_cs_DE3', 'v252_cs_GB1', 'v252_cs_GB2']\n",
    "df_train.drop(columns=v252_to_drop, inplace=True)\n",
    "df_test.drop(columns=v252_to_drop, inplace=True)\n",
    "\n",
    "\n",
    "# ### Kind of job partner variables drop\n",
    "# keep v255_ESeC: kind of job spouse/partner\n",
    "v255_to_drop = ['v255_ISCO_2', 'v255_SIOPS', 'v255_ISEI', 'v255_egp']\n",
    "df_train.drop(columns=v255_to_drop, inplace=True)\n",
    "df_test.drop(columns=v255_to_drop, inplace=True)\n",
    "\n",
    "\n",
    "################################################### Households income variables to drop ################################################\n",
    "df_train.drop('v261_ppp', inplace=True, axis=1)\n",
    "df_test.drop('v261_ppp', inplace=True, axis=1)\n",
    "\n",
    "\n",
    "################################################## education level father/mother variables drop ################################################\n",
    "\n",
    "# keep v262_cs: educational level father: ESS-edulvlb coding two digits \n",
    "v262_to_drop = ['v262_edulvlb', 'v262_edulvlb_1', 'v262_ISCED_3', 'v262_ISCED_2', 'v262_ISCED_2b', 'v262_ISCED_1', 'v262_EISCED', 'v262_ISCED97', \n",
    "                'v262_8cat', 'v262_r', 'v262_edulvlb_2', 'v262_cs_DE1', 'v262_cs_DE2', 'v262_cs_DE3', 'v262_cs_GB1', 'v262_cs_GB2']\n",
    "df_train.drop(columns=v262_to_drop, inplace=True)\n",
    "df_test.drop(columns=v262_to_drop, inplace=True)\n",
    "\n",
    "# keep v263_cs:educational level mother: ESS-edulvlb coding two digits\n",
    "v263_to_drop = ['v263_edulvlb', 'v263_edulvlb_2', 'v263_edulvlb_1', 'v263_ISCED_3', 'v263_ISCED_2', 'v263_ISCED_2b', 'v263_ISCED_1', 'v263_EISCED',\n",
    "                 'v263_ISCED97', 'v263_8cat', 'v263_r', 'v263_edulvlb_2', 'v263_cs_DE1', 'v263_cs_DE2', 'v263_cs_DE3', 'v263_cs_GB1', 'v263_cs_GB2']\n",
    "df_train.drop(columns=v263_to_drop, inplace=True)\n",
    "df_test.drop(columns=v263_to_drop, inplace=True)\n",
    "\n",
    "\n",
    "################################################### Interview dates variables drop ########################################################################\n",
    "# v277: date of interview \n",
    "# v278a: time of interview: start hour \n",
    "# v278b: time of interview: start minute \n",
    "# v278c_r: time of interview: start  \n",
    "# v279a: time of interview: end hour \n",
    "# v279b: time of interview: end minute \n",
    "# v279c_r: time of interview: end \n",
    "# v279d_r: time of interview: duration in minutes \n",
    "\n",
    "##### Keep v278a, v279d_r -- Duration in miniutes\n",
    "times_to_drop = ['v277', 'v278b', 'v278c_r', 'v279a', 'v279b', 'v279c_r']\n",
    "df_train.drop(columns=times_to_drop, inplace=True)\n",
    "df_test.drop(columns=times_to_drop, inplace=True)\n",
    "\n",
    "\n",
    "############################################################### MERGE COLUMNS ##############################################################\n",
    "merge_colname = find_colname_end(df_train, '_11c')\n",
    "merge_columns(df_train, merge_colname)\n",
    "merge_columns(df_test, merge_colname)\n",
    "\n",
    "# print(find_colname(train_x_raw, 'c', 'endwith'))\n",
    "# print(find_colname(train_x_raw, '_r', 'endwith'))\n",
    "### Find variables containing _cs and do SimpleAggregation\n",
    "# print(find_colname(df_train, '_cs', 'endwith'))\n",
    "#aggregatecol = find_colname_end(df_train, '_cs')\n",
    "#simpleAggregation(aggregatecol) #### TRAIN/TEST BOTH APPLICABLE\n",
    "\n",
    "\n",
    "########################################################## TIME FIX ##################################################\n",
    "### Convert fw_start ==> Start month of fw\n",
    "### Convert fw_end ==> Duration of fw\n",
    "timeEDA(df_train)\n",
    "timeEDA(df_test)\n",
    "\n",
    "\n",
    "################################################ 'DE' / 'GB' Country Specific Dropped ##################################################\n",
    "\n",
    "\n",
    "## removed the column having 'GB'\n",
    "df_train.drop(list(df_train.filter(regex='DE')), axis=1, inplace=True)\n",
    "df_test.drop(list(df_test.filter(regex='DE')), axis=1, inplace=True)\n",
    "\n",
    "## removed the column having 'GB'\n",
    "df_train.drop(list(df_train.filter(regex='GB')), axis=1, inplace=True)\n",
    "df_test.drop(list(df_test.filter(regex='GB')), axis=1, inplace=True)\n",
    "\n",
    "\n",
    "columns_to_drop = ['v24a_IT', 'v52', 'v54', 'v64', 'f96', 'v102', 'v129', 'v172', 'v184', 'v171', 'v215', 'v174_LR']\n",
    "df_train.drop(columns=columns_to_drop, inplace=True, axis=1)\n",
    "df_test.drop(columns=columns_to_drop, inplace=True, axis=1)\n",
    "\n",
    "##################################################### ONE HOT ENCODING ##################################################\n",
    "columns_to_drop = ['v228b_r','v231b_r','v233b_r','v251b_r','v275c_N2', 'v275c_N1', 'v281a_r']\n",
    "df_train.drop(columns=columns_to_drop, inplace=True)\n",
    "df_test.drop(columns=columns_to_drop, inplace=True)\n",
    "\n",
    "columns_to_encode = ['v228b', 'v231b', 'v233b', 'v251b', 'v275b_N1', 'v275b_N2', 'v281a']\n",
    "columns_to_encode += find_colname_end(df_train, '_cs')\n",
    "columns_to_encode += ['v246_ESeC','v255_ESeC']\n",
    "\n",
    "df_train = pd.get_dummies(df_train, columns=columns_to_encode)\n",
    "df_test = pd.get_dummies(df_test, columns=columns_to_encode)\n",
    "df_train = df_train.reindex(columns = sorted(df_train.columns))\n",
    "df_test = df_test.reindex(columns = sorted(df_test.columns))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nothing done.\n"
     ]
    }
   ],
   "source": [
    "columns_to_encode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################### CORRELATION CHECKUP ##########################################################################\n",
    "corr = df_train.corr()\n",
    "pairs = []\n",
    "\n",
    "for i in range(len(corr.columns)):\n",
    "    for j in range(i+1, len(corr.columns)):  # i+1 to exclude self-correlation\n",
    "        if (0.95 <= corr.iloc[i, j] <= 1) or (-1 <= corr.iloc[i, j] <= -0.95):\n",
    "            pairs.append((corr.columns[i], corr.columns[j]))\n",
    "\n",
    "\n",
    "set_pairs = []\n",
    "\n",
    "for e in pairs:\n",
    "     set_pairs.append(set(e))\n",
    "\n",
    "x = list(set().union(*set_pairs))\n",
    "\n",
    "dic = {}\n",
    "for e in x:\n",
    "    dic[e] = df_train[e].corr(df_y['label'])\n",
    "\n",
    "remainder = []\n",
    "for i in set_pairs:\n",
    "    i = list(i)\n",
    "    if abs(dic[i[0]]) > abs(dic[i[1]]):\n",
    "        remainder.append(i[0])\n",
    "    else:\n",
    "        remainder.append(i[1])\n",
    "dropped = []\n",
    "for i in set_pairs:\n",
    "    i = list(i)\n",
    "    if abs(dic[i[0]]) < abs(dic[i[1]]):\n",
    "        dropped.append(i[0])\n",
    "    else:\n",
    "        dropped.append(i[1])\n",
    "for e in dropped:\n",
    "    if not e in df_train.columns :\n",
    "        continue\n",
    "    df_train.drop(e, inplace=True, axis=1)\n",
    "    df_test.drop(e, inplace=True, axis=1)\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
